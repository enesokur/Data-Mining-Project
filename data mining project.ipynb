{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ydsw2DQ81BkZ",
        "outputId": "4f82c888-2173-4cd0-f967-82657cebcaf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for gini index using holdout method\n",
            "Precision: %87.07\n",
            "Recall: %91.74\n",
            "F1: %89.34\n",
            "Accuracy: %88.0\n",
            "[[474  94]\n",
            " [ 57 633]]\n",
            "\n",
            "Results for gain ratio using 10K cross validation method.\n",
            "Precision: [0.         0.         0.         0.         0.92565056 1.\n",
            " 1.         1.         1.         1.        ]\n",
            "Recall: [0.         0.         0.         0.         0.90181818 0.88976378\n",
            " 0.91076115 0.90026247 0.8976378  0.90026247]\n",
            "F1: [0.         0.         0.         0.         0.91575092 0.93723849\n",
            " 0.95185695 0.94459834 0.93426573 0.94313454]\n",
            "Accuracy [0.8976378  0.85301837 0.85826772 0.77165354 0.87664042 0.8976378\n",
            " 0.91076115 0.8976378  0.88188976 0.88188976]\n",
            "\n",
            "Results for gain ratio using holdout method\n",
            "Precision: %88.24\n",
            "Recall: %90.29\n",
            "F1: %89.26\n",
            "Accuracy: %88.08\n",
            "[[485  83]\n",
            " [ 67 623]]\n",
            "\n",
            "Results for bayes model using holdout method\n",
            "Precision: %92.25\n",
            "Recall: %94.93\n",
            "F1: %93.57\n",
            "Accuracy: %92.85\n",
            "[[513  55]\n",
            " [ 35 655]]\n",
            "\n",
            "Result for neural network with 1 hidden layer using holdout method.\n",
            "Precision: %92.05\n",
            "Recall: %95.65\n",
            "F1: %93.82\n",
            "Accuracy: %93.08\n",
            "[[511  57]\n",
            " [ 30 660]]\n",
            "\n",
            "Result for neural network with 2 hidden layer using holdout method.\n",
            "Precision: %92.06\n",
            "Recall: %95.8\n",
            "F1: %93.89\n",
            "Accuracy: %93.16\n",
            "[[511  57]\n",
            " [ 29 661]]\n",
            "\n",
            "Result for support vector machines using holdout method.\n",
            "Precision: %92.19\n",
            "Recall: %95.8\n",
            "F1: %93.96\n",
            "Accuracy: %93.24\n",
            "[[512  56]\n",
            " [ 29 661]]\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import arff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import svm\n",
        "\n",
        "#method for evaluating predictions\n",
        "def evaluate_model(y_pred,y_test):\n",
        "  print(\"Precision:\", \"%\" + str(round(precision_score(y_test, y_pred)*100,2)))\n",
        "  print(\"Recall:\", \"%\" + str(round(recall_score(y_test, y_pred)*100,2)))\n",
        "  print(\"F1:\", \"%\" + str(round(f1_score(y_test, y_pred)*100,2)))\n",
        "  print(\"Accuracy:\", \"%\" + str(round(accuracy_score(y_test, y_pred)*100,2)))\n",
        "  confusionmatrix = confusion_matrix(y_test,y_pred)\n",
        "  print(confusionmatrix)\n",
        "\n",
        "\n",
        "rawdata = arff.loadarff('/content/drive/MyDrive/Rice_Cammeo_Osmancik.arff')\n",
        "df = pd.DataFrame(rawdata[0])\n",
        "\n",
        "\n",
        "#normalizing data\n",
        "scaler = MinMaxScaler()\n",
        "classifications_reshaped = tf.reshape(df.values[:,7:8],(3810,1))\n",
        "values_without_classifications =  df.values[:,:7]\n",
        "scaled_values = scaler.fit_transform(values_without_classifications)\n",
        "scaled_data = np.append(scaled_values,classifications_reshaped,axis=1)\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
        "\n",
        "#transforming labels to int\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(scaled_df.Class)\n",
        "scaled_df['Class'] = le.transform(scaled_df.Class)\n",
        "\n",
        "X = scaled_df.values[:,:7]\n",
        "y = scaled_df.values[:,7:8]\n",
        "\n",
        "#splitting data using holdout method.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "#constructing classifier for gini index.\n",
        "gini_classifier = DecisionTreeClassifier(criterion=\"gini\")\n",
        "gini_model = gini_classifier.fit(X_train,y_train.astype(\"int\"))\n",
        "gini_predict = gini_model.predict(X_test)\n",
        "print(\"Results for gini index using holdout method\")\n",
        "evaluate_model(tf.reshape(gini_predict.astype('int'),(1258,1)),y_test.astype('int'))\n",
        "\n",
        "#constructing classifier for gain ratio using cross validation.\n",
        "gain_classifier = DecisionTreeClassifier(criterion=\"log_loss\")\n",
        "cross_val = KFold(n_splits=10)\n",
        "precision_scores = cross_val_score(gain_classifier, X, y.astype('int'), scoring='precision', cv=cross_val, n_jobs=-1)\n",
        "recall_scores = cross_val_score(gain_classifier, X, y.astype('int'), scoring='recall', cv=cross_val, n_jobs=-1)\n",
        "f1_scores = cross_val_score(gain_classifier, X, y.astype('int'), scoring='f1', cv=cross_val, n_jobs=-1)\n",
        "accuracy_scores = cross_val_score(gain_classifier, X, y.astype('int'), scoring='accuracy', cv=cross_val, n_jobs=-1)\n",
        "print(\"\\nResults for gain ratio using 10K cross validation method.\")\n",
        "print(\"Precision:\",precision_scores)\n",
        "print(\"Recall:\",recall_scores)\n",
        "print(\"F1:\",f1_scores)\n",
        "print(\"Accuracy\",accuracy_scores)\n",
        "\n",
        "#constructing classifier for gain ratio using holdout method.\n",
        "gain_classifier_holdout = DecisionTreeClassifier(criterion=\"log_loss\")\n",
        "gain_model = gain_classifier_holdout.fit(X_train,y_train.astype(\"int\"))\n",
        "gain_predict = gain_model.predict(X_test)\n",
        "print(\"\\nResults for gain ratio using holdout method\")\n",
        "evaluate_model(tf.reshape(gain_predict.astype('int'),(1258,1)),np.ravel(y_test.astype('int')))\n",
        "\n",
        "#constructing classifier for naive bayes\n",
        "bayes_classifier = GaussianNB()\n",
        "bayes_model = bayes_classifier.fit(X_train,np.ravel(y_train.astype(\"int\")))\n",
        "bayes_predict = bayes_model.predict(X_test)\n",
        "print(\"\\nResults for bayes model using holdout method\")\n",
        "evaluate_model(tf.reshape(bayes_predict.astype(\"int\"),(1258,1)),np.ravel(y_test.astype(\"int\")))\n",
        "\n",
        "#constructing classifier for neural network with 1 hidden layer\n",
        "NN_classifier = MLPClassifier(hidden_layer_sizes=(10),max_iter=500,activation = 'relu',solver='adam')\n",
        "NN_model = NN_classifier.fit(X_train,np.ravel(y_train.astype(\"int\")))\n",
        "NN_predict = NN_model.predict(X_test)\n",
        "print(\"\\nResult for neural network with 1 hidden layer using holdout method.\")\n",
        "evaluate_model(tf.reshape(NN_predict.astype(\"int\"),(1258,1)),np.ravel(y_test.astype(\"int\")))\n",
        "\n",
        "#constructing classifier for neural network with 2 hidden layer\n",
        "NN_classifier2 = MLPClassifier(hidden_layer_sizes=(10,10),max_iter=500,activation = 'relu',solver='adam')\n",
        "NN_model2 = NN_classifier2.fit(X_train,np.ravel(y_train.astype(\"int\")))\n",
        "NN_predict2 = NN_model2.predict(X_test)\n",
        "print(\"\\nResult for neural network with 2 hidden layer using holdout method.\")\n",
        "evaluate_model(tf.reshape(NN_predict2.astype(\"int\"),(1258,1)),np.ravel(y_test.astype(\"int\")))\n",
        "\n",
        "#constructing classifier for support vector machines\n",
        "svm_classifier = svm.SVC(kernel='linear')\n",
        "svm_model = svm_classifier.fit(X_train, np.ravel(y_train.astype(\"int\")))\n",
        "svm_predict = svm_model.predict(X_test)\n",
        "print(\"\\nResult for support vector machines using holdout method.\")\n",
        "evaluate_model(tf.reshape(svm_predict.astype(\"int\"),(1258,1)),np.ravel(y_test.astype(\"int\")))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SgiyzX59h9z8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}